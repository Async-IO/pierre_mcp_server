# Pierre MCP Server - Code Quality Validation Patterns
# This file defines patterns that indicate poor code quality, placeholder implementations,
# or other anti-patterns that should be caught by the validation suite.

[placeholder_patterns]
# Critical failures - code that pretends to work but doesn't
# These patterns indicate Claude Code has left placeholder implementations
critical = [
    "Implementation would",
    "Would implement",
    "Should implement",
    "Will implement",
    "TODO: Implementation",
    "Available for real implementation",
    "available for real implementation",
    "Implement the code",
    "stub implementation",
    "stub for now",
    "stub endpoint",
    "requires.*parameter implementation",
    "mock implementation",
    "placeholder implementation",
    "placeholder structure",
    "simplified placeholder",
    "using.*placeholder",
    "this is a placeholder",
    "is a placeholder that",
    "will be implemented",
    "to be implemented",
    "return mock data",
    "using mock data",
    "fake implementation",
    "unimplemented!",
    "todo!",
    "return Ok\\(\\); // placeholder",
    "return Err.*not implemented",
    "not yet.*implemented",
    "Intelligence analysis requires authenticated provider access",
    "requires authenticated provider access",
    "This handler.*delegates to.*services",
    "success: false,\\s*result: None,\\s*error: Some"
]

# Migration/compatibility patterns - should be rare and justified
# These are acceptable in limited cases but often indicate lazy implementation
migration = [
    "Legacy field for backward compatibility",
    "backward compatibility during migration",
    "// In future versions",
    "// will be implemented",
    "// can be extended",
    "// to be added"
]

# Hedge language - avoiding commitment
# These patterns indicate uncertainty or incomplete implementation
hedge_language = [
    "might implement",
    "could implement",
    "should handle",
    "potentially",
    "possibly",
    "This allows for",
    "Provides support for",
    "Based on configuration",
    "According to settings",
    "if needed",
    "as needed",
    "when required",
    "depending on"
]

# Vague authoritative language - sounds implemented but may be generic
# These are often legitimate but worth reviewing for specificity
vague_authoritative = [
    "This handles",
    "Processes",
    "Manages",
    "Automatically handles",
    "Seamlessly integrates",
    "Handles all",
    "Takes care of",
    "Deals with"
]

# Future tense evasion - pushing work to imaginary future
future_evasion = [
    "once we",
    "when we",
    "after we",
    "needs to be",
    "must be",
    "should be",
    "will need",
    "requires implementation"
]

# Improvement promises - vague commitments to do better later
improvement_promises = [
    "handle this properly",
    "implement properly",
    "add proper",
    "extend this",
    "improve this",
    "enhance this",
    "refactor this",
    "optimize later",
    "consider caching",
    "performance improvement"
]

# Validation/security shortcuts - security theater
security_shortcuts = [
    "Add validation",
    "Validate input",
    "Check permissions",
    "Sanitize input",
    "Add security",
    "Encrypt this",
    "Authorize user",
    "Authentication needed"
]

# Error handling evasion - not actually handling errors
error_handling_evasion = [
    "Handle error properly",
    "Add error handling",
    "Improve error",
    "Catch exceptions",
    "Error recovery",
    "Graceful failure"
]

# Configuration punts - making everything "configurable" instead of implementing
configuration_punts = [
    "Make configurable",
    "Add configuration",
    "Configure properly",
    "Environment dependent"
]

# Documentation shortcuts - promising docs instead of clear code
documentation_shortcuts = [
    "Document this",
    "Add documentation",
    "API docs needed",
    "Usage examples",
    "Add comments"
]

# Error handling anti-patterns - avoiding proper error handling
unwrap_patterns = [
    "\\.unwrap\\(\\)"
]

expect_patterns = [
    "\\.expect\\("
]

panic_patterns = [
    "panic!\\("
]

# Development artifacts that shouldn't be in production
development_artifacts = [
    "// TODO",
    "// FIXME",
    "// XXX",
    "#\\[allow\\(dead_code\\)\\]",
    "#\\[cfg\\(test\\)\\]",
    "#\\[ignore\\]"
]

# Production hygiene - test artifacts in production code
production_hygiene = [
    "example\\.com",
    "test@.*\\.com",
    "mock_",
    "get_mock",
    "return.*mock",
    "demo purposes",
    "for demo"
]

# Magic input anti-patterns - tools that generate fake data based on special input values
# These patterns detect when tools bypass real data requirements by accepting "magic" parameters
# Example anti-pattern: calculate_recovery_score({ "provider": "synthetic" }) generates internal fake data
# Correct pattern: calculate_recovery_score({ "sleep_data": {...} }) requires explicit real input
magic_input_antipatterns = [
    "SyntheticProvider::new\\(\\)",                    # Direct synthetic provider instantiation in tool handlers
    "SyntheticProvider::from_seed",                    # Seeded synthetic provider in tool handlers
    "generate_.*_data\\(",                             # Functions that generate data internally
    "create_synthetic_",                               # Functions that create synthetic data
    "if.*provider.*==.*\"synthetic\"",                 # Conditional logic based on synthetic provider
    "match.*provider.*synthetic",                      # Match arms for synthetic provider in tools
]

# Temporary solutions - code that should be permanent
temporary_code = [
    "\\bhack\\b",
    "\\bworkaround\\b",
    "quick.*fix",
    "temporary.*solution",
    "temp.*fix"
]

# Clippy suppressions - avoiding proper fixes
clippy_suppressions = [
    "#\\[allow\\(clippy::.*\\)\\]"
]

# Long function suppressions - undocumented functions that should be decomposed
long_function_suppressions = [
    "#\\[allow\\(clippy::too_many_lines\\)\\]"
]

# Documented long function suppressions - these have justification comments and are acceptable
documented_long_functions = [
    "// Long function:.*\n.*#\\[allow\\(clippy::too_many_lines\\)\\]",
    "// Safe:.*\n.*#\\[allow\\(clippy::too_many_lines\\)\\]"
]

# Problematic naming patterns
problematic_naming = [
    "fn _[a-zA-Z]",
    "let _[a-zA-Z]",
    "struct _[a-zA-Z]",
    "enum _[a-zA-Z]"
]

# Magic numbers - large hardcoded values
magic_numbers = [
    "\\b[0-9]{4,}\\b"
]

# Architectural patterns - design anti-patterns and obsolete code
resource_creation = [
    "AuthManager::new",
    "OAuthManager::new",
    "A2AClientManager::new",
    "TenantOAuthManager::new"
]

fake_resources = [
    "Arc::new\\(ServerResources\\s*[\\{\\:]"
]

obsolete_functions = [
    "fn.*run_http_server\\("
]

unused_variables = [
    "#\\[allow\\(unused.*\\)\\]"
]

deprecated_code = [
    "#\\[deprecated\\]"
]

# Memory management patterns - cloning and Arc usage analysis
legitimate_arc_clones = [
    "database_arc\\.clone\\(\\)"
]

problematic_db_clones = [
    "\\.as_ref\\(\\)\\.clone\\(\\)"
]

arc_usage = [
    "Arc::"
]

clone_usage = [
    "\\.clone\\(\\)"
]

# Legitimate clone patterns - patterns that are acceptable for cloning
legitimate_clone_patterns = [
    "Arc::",
    "resources\\.",
    "database\\.",
    "auth_manager\\.",
    "sse_manager\\.",
    "websocket_manager\\.",
    "\\.to_string\\(\\)",
    "format!",
    "String::from",
    "token",
    "url",
    "name",
    "path",
    "message",
    "error",
    "Error",
    "client_id",
    "client_secret",
    "redirect_uri",
    "access_token",
    "refresh_token",
    "user_id",
    "tenant_id",
    "request\\.",
    "response\\.",
    "context\\.",
    "config\\.",
    "profile\\."
]

# Claude Code Anti-Patterns - Patterns that AI code generators commonly create
# These catch non-idiomatic Rust that looks correct but isn't optimal

# String allocation anti-patterns - unnecessary String where &str would work
# Note: Excludes constructors (::new) which legitimately need ownership
string_allocation_antipatterns = [
    "\\.to_string\\(\\)\\.as_str\\(\\)",  # Unnecessary round-trip
    "String::from.*\\.as_str\\(\\)"       # Another round-trip
]

# Function parameter String usage - needs manual review (constructors are often legitimate)
function_string_parameters = [
    "pub fn (?!new|error|cancelled)\\w+\\(.*: String,"  # Non-constructor functions with String params
]

# Iterator anti-patterns - manual loops where iterators would be cleaner
iterator_antipatterns = [
    "let mut.*vec.*=.*Vec::new\\(\\);\\s*for",  # Mutable vec + manual loop (use collect)
    "let mut.*count.*=.*0;\\s*for.*\\{\\s*count",  # Manual counting (use .count())
    "for.*in.*\\{\\s*if.*\\{\\s*return.*\\}\\s*\\}",  # Manual find (use .find())
]

# Error context anti-patterns - FORBIDDEN anyhow! macro usage (CLAUDE.md: use structured error types only)
error_context_antipatterns = [
    "anyhow::anyhow!\\(",            # Fully qualified anyhow! macro - FORBIDDEN
    "\\banyhow!\\(",                 # Shorthand anyhow! macro - FORBIDDEN
    "Err\\(anyhow!\\(",              # Err(anyhow!(...)) pattern - FORBIDDEN
    "\\.map_err\\(.*anyhow!\\(",     # .map_err(|_| anyhow!(...)) - FORBIDDEN
    "\\.ok_or_else\\(.*anyhow!\\(",  # .ok_or_else(|| anyhow!(...)) - FORBIDDEN
    "\\?.*anyhow!\\(",               # chained with ? operator - FORBIDDEN
]

# Anyhow import anti-patterns - use structured AppResult/AppError instead (CLAUDE.md: structured errors only)
anyhow_import_antipatterns = [
    "use anyhow::",                  # Any anyhow import - use crate::errors instead
    "use anyhow;",                   # Blanket anyhow import - FORBIDDEN
]

# Anyhow type anti-patterns - use AppResult<T> instead of anyhow::Result (CLAUDE.md: structured errors only)
anyhow_type_antipatterns = [
    "anyhow::Result",                # Should be AppResult<T>
    "Result<.*anyhow::Error>",       # Should be AppResult<T>
    "-> Result<.*anyhow",            # Function returns anyhow types
]

# Anyhow method anti-patterns - use .map_err() with AppError instead of .context()
anyhow_method_antipatterns = [
    "\\.context\\(",                 # anyhow's .context() - use .map_err() instead
]

# Async anti-patterns - blocking operations in async contexts
async_antipatterns = [
    "async fn.*std::fs::",          # Blocking file I/O in async
    "async fn.*std::thread::sleep", # Blocking sleep in async
    "async fn.*\\.lock\\(\\)\\.unwrap", # Blocking mutex lock in async (use tokio::sync)
]

# Lifetime complexity anti-patterns - over-specified lifetimes
# Note: Patterns with single quotes disabled due to shell escaping complexity
lifetime_antipatterns = [
    "DISABLED_static_lifetime_pattern",  # Triple static lifetimes (pattern disabled)
    "DISABLED_multiple_lifetime_pattern", # Four or more lifetime parameters (pattern disabled)
]

[validation_config]
# Which pattern groups cause critical failures (script exits with error)
critical_groups = ["critical", "unwrap_patterns", "expect_patterns", "panic_patterns", "production_hygiene", "fake_resources"]

# Which pattern groups are warnings only (logged but don't fail build)
# Note: Claude Code anti-patterns have dedicated validation rows and should not be in warning_groups
warning_groups = [
    "development_artifacts",
    "obsolete_functions",
    "deprecated_code"
]

# Pattern groups with thresholds (count-based validation)
threshold_groups = ["magic_numbers", "arc_usage", "clone_usage"]

# Pattern groups for architectural analysis (informational)
architectural_groups = ["legitimate_arc_clones", "problematic_db_clones", "legitimate_clone_patterns", "documented_long_functions"]

# Validation thresholds for count-based checks
[validation_thresholds]
max_magic_numbers = 10
max_clippy_allows = 5
max_arc_usage = 50
max_total_clones = 600
max_development_artifacts = 20
max_temporary_code = 5
max_resource_creation = 0
max_obsolete_functions = 0
max_unused_variables = 5
max_deprecated_code = 0
max_fake_resources = 0
max_problematic_db_clones = 0

# Claude Code anti-pattern thresholds
max_string_allocation_antipatterns = 0  # Round-trip conversions should never occur
max_function_string_parameters = 0      # All fixed - functions should use &str
max_iterator_antipatterns = 15
max_error_context_antipatterns = 0  # ZERO TOLERANCE: anyhow! macro is FORBIDDEN (use structured error types)
max_anyhow_import_antipatterns = 0  # ZERO TOLERANCE: use AppResult/AppError instead of anyhow imports
max_anyhow_type_antipatterns = 0    # ZERO TOLERANCE: use AppResult<T> instead of anyhow::Result
max_anyhow_method_antipatterns = 20 # WARNING ONLY: .context() should migrate to .map_err() (20 existing uses in providers)
max_async_antipatterns = 5
max_lifetime_antipatterns = 3
max_magic_input_antipatterns = 0  # ZERO TOLERANCE: tools must require explicit input, not generate fake data

# File patterns to exclude from certain checks
[ignored_tests_allowlist]
# Files permitted to have #[ignore] tests with justification
# These require external infrastructure that CI cannot provide
files = [
    "llm_local_integration_test.rs",   # Requires Ollama/vLLM server with downloaded models
    "llm_openai_compatible_test.rs",   # Requires running Ollama server for API tests
]

[ci_continue_on_error_allowlist]
# Workflow steps permitted to have continue-on-error: true
# Format: "workflow_file:step_name" or "workflow_file:line_number"
# Only add entries after explicit approval with documented justification
allowed = [
]

[js_test_skip_allowlist]
# Test files permitted to have .skip(), .only(), xit(), xdescribe()
# Only add entries after explicit approval with documented justification
allowed = [
]

[exclusions]
# Files where some patterns might be legitimate
test_files = ["tests/**", "**/*_test.rs", "**/test_*.rs"]
example_files = ["examples/**", "**/examples/**"]
bin_files = ["src/bin/**"]

# Error handling exclusions - files where unwrap/expect might be acceptable
error_handling_exclusions = [
    "src/bin/**",
    "tests/**",
    "**/*_test.rs"
]

# Development artifacts exclusions - files where TODO/FIXME are acceptable
development_artifacts_exclusions = [
    "tests/**",
    "examples/**"
]

# Magic numbers exclusions - files where large numbers are expected
magic_numbers_exclusions = [
    "src/constants.rs",
    "src/config/**",
    "**/migrations/**"
]

[allowed_patterns]
# These are legitimate uses that shouldn't trigger failures
legitimate_backward_compatibility = [
    "Type alias for backward compatibility - use .* directly in new code",
    "Legacy method.*for backward compatibility",
    "Deprecated.*use.*instead"
]

legitimate_fallback = [
    "Fall back to.*configuration",
    "Fall back to.*default",
    "Fall back to.*credentials"
]

legitimate_handles = [
    "This.*handles.*requests",
    "Handles.*HTTP.*requests",
    "handles.*database.*operations"
]

# ============================================================================
# Algorithm DI Architecture - Enum-Based Dependency Injection Enforcement
# ============================================================================
# These patterns detect hardcoded algorithm formulas that should use enum-based DI
# All algorithms must be implemented in src/intelligence/algorithms/ as enums

[algorithm_di_patterns]
# Algorithms that have been migrated to enum-based DI
migrated_algorithms = ["maxhr", "trimp", "tss", "vdot", "ctl_atl_tsb", "recovery_score", "ftp", "lthr", "vo2max"]

# MaxHR formula detection patterns
[algorithm_di_patterns.maxhr]
name = "MaxHR"
enum_name = "MaxHrAlgorithm"
module_path = "src/intelligence/algorithms/maxhr.rs"
exclude_paths = ["src/intelligence/algorithms/maxhr.rs"]

[algorithm_di_patterns.maxhr.formulas]
fox = 'let.*=.*220\.0.*-|220\.0\s*-\s*f64::from|=\s*220\s*-\s*age|return.*220.*-.*age'
tanaka = 'let.*=.*208.*-.*0\.7|=\s*208\s*-\s*0\.7|0\.7f64.*mul_add.*-.*208'
nes = 'let.*=.*211.*-.*0\.64|=\s*211\s*-\s*0\.64|0\.64f64.*mul_add.*-.*211'
gulati = 'let.*=.*206.*-.*0\.88|=\s*206\s*-\s*0\.88|0\.88f64.*mul_add.*-.*206'

# TRIMP formula detection patterns
[algorithm_di_patterns.trimp]
name = "TRIMP"
enum_name = "TrimpAlgorithm"
module_path = "src/intelligence/algorithms/trimp.rs"
exclude_paths = ["src/intelligence/algorithms/trimp.rs", "src/intelligence/physiological_constants.rs"]

[algorithm_di_patterns.trimp.formulas]
male_coefficient = '=>\s*1\.92|:\s*f64\s*=\s*1\.92|gender_factor.*1\.92|let.*=.*1\.92.*Male|TRIMP.*1\.92'
female_coefficient = '=>\s*1\.67|:\s*f64\s*=\s*1\.67|gender_factor.*1\.67|let.*=.*1\.67.*[Ff]emale'
base_multiplier = 'hr_ratio\s*\*\s*0\.64|0\.64\s*\*.*hr_ratio|\*\s*0\.64\s*\*.*gender_factor'

# TSS formula detection patterns
[algorithm_di_patterns.tss]
name = "TSS"
enum_name = "TssAlgorithm"
module_path = "src/intelligence/algorithms/tss.rs"
exclude_paths = ["src/intelligence/algorithms/tss.rs", "src/intelligence/training_load.rs"]

[algorithm_di_patterns.tss.formulas]
power_formula = '\(power\s*/\s*ftp\)\.powi\(2\)|\(power\s*/\s*ftp\)\s*\*\s*\(power\s*/\s*ftp\)|intensity_factor\s*\*\s*intensity_factor\s*\*\s*(100|TSS_BASE_MULTIPLIER)'

# VDOT formula detection patterns (Jack Daniels' running performance)
[algorithm_di_patterns.vdot]
name = "VDOT"
enum_name = "VdotAlgorithm"
module_path = "src/intelligence/algorithms/vdot.rs"
exclude_paths = ["src/intelligence/algorithms/vdot.rs", "src/intelligence/performance_prediction.rs"]

[algorithm_di_patterns.vdot.formulas]
daniels_vo2_formula = '-4\.60|0\.182258|0\.182_258|0\.000104|0\.000_104'
velocity_calculation = '\(distance.*\/.*time\)\s*\*\s*60\.0'

# CTL/ATL/TSB formula detection patterns (Training Load)
[algorithm_di_patterns.ctl_atl_tsb]
name = "CTL/ATL/TSB"
enum_name = "TrainingLoadAlgorithm"
module_path = "src/intelligence/algorithms/training_load.rs"
exclude_paths = ["src/intelligence/algorithms/training_load.rs", "src/intelligence/training_load.rs"]

[algorithm_di_patterns.ctl_atl_tsb.formulas]
ctl_window = 'const\s+CTL_WINDOW.*=.*42|let.*ctl.*window.*=.*42'
atl_window = 'const\s+ATL_WINDOW.*=.*7|let.*atl.*window.*=.*7'
tsb_formula = 'tsb.*=.*ctl\s*-\s*atl|TSB.*CTL.*ATL'

# Recovery Score formula detection patterns
[algorithm_di_patterns.recovery_score]
name = "Recovery Score"
enum_name = "RecoveryScoreAlgorithm"
module_path = "src/intelligence/algorithms/recovery.rs"
# Note: OAuth scope files excluded to avoid false positives from "sleep ... weight" scope strings
# Tool implementation files excluded as they pass configuration values, not implement formulas
exclude_paths = ["src/intelligence/algorithms/recovery.rs", "src/intelligence/algorithms/recovery_aggregation.rs", "src/intelligence/recovery_calculator.rs", "src/protocols/universal/handlers/sleep_recovery.rs", "src/config/intelligence/*", "src/constants/oauth/*", "src/config/oauth.rs", "src/providers/spi.rs", "src/tools/implementations/sleep.rs", "tests/*"]

[algorithm_di_patterns.recovery_score.formulas]
score_calculation = 'overall_score.*=.*(tsb.*\+.*sleep|sleep.*\+.*tsb)'
component_weights = 'tsb.*weight|sleep.*weight|hrv.*weight'

# FTP formula detection patterns (Functional Threshold Power)
[algorithm_di_patterns.ftp]
name = "FTP"
enum_name = "FtpAlgorithm"
module_path = "src/intelligence/algorithms/ftp.rs"
exclude_paths = ["src/intelligence/algorithms/ftp.rs", "src/config/vo2_max.rs"]

[algorithm_di_patterns.ftp.formulas]
twenty_min_test = '0\.95.*power|power.*0\.95'
eight_min_test = '0\.90.*power|power.*0\.90'
ramp_test = '0\.75.*max.*power|max.*power.*0\.75'

# LTHR formula detection patterns (Lactate Threshold Heart Rate)
[algorithm_di_patterns.lthr]
name = "LTHR"
enum_name = "LthrAlgorithm"
module_path = "src/intelligence/algorithms/lthr.rs"
exclude_paths = ["src/intelligence/algorithms/lthr.rs"]

[algorithm_di_patterns.lthr.formulas]
from_maxhr = 'max_hr.*0\.8[5-9]|max_hr.*0\.9[01]'
from_thirty_min = 'avg_hr.*1\.03|1\.03.*avg_hr'

# VO2max formula detection patterns
[algorithm_di_patterns.vo2max]
name = "VO2max"
enum_name = "Vo2maxAlgorithm"
module_path = "src/intelligence/algorithms/vo2max.rs"
exclude_paths = ["src/intelligence/algorithms/vo2max.rs", "src/configuration/vo2_max.rs"]

[algorithm_di_patterns.vo2max.formulas]
from_vdot = 'vdot.*3\.5|3\.5.*vdot'
cooper_test = 'distance.*-.*504\.9|504\.9'
from_pace = '15\.3.*speed|speed.*15\.3'